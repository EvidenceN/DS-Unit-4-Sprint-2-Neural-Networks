{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Backpropagation-Practice\" data-toc-modified-id=\"Backpropagation-Practice-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Backpropagation Practice</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Science-Unit-4-Sprint-2-Assignment-2\" data-toc-modified-id=\"Data-Science-Unit-4-Sprint-2-Assignment-2-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><em>Data Science Unit 4 Sprint 2 Assignment 2</em></a></span></li><li><span><a href=\"#Try-building/training-a-more-complex-MLP-on-a-bigger-dataset.\" data-toc-modified-id=\"Try-building/training-a-more-complex-MLP-on-a-bigger-dataset.-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Try building/training a more complex MLP on a bigger dataset.</a></span></li><li><span><a href=\"#Stretch-Goals:\" data-toc-modified-id=\"Stretch-Goals:-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Stretch Goals:</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Backpropagation Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 0  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 1 |\n",
    "| 0  | 1  | 0  | 1 |\n",
    "| 1  | 0  | 0  | 1 |\n",
    "| 1  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 0  | 0 |\n",
    "\n",
    "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEREYT-3wI1f"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "# create dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'x1': [0,0,1,0,1,1,0],\n",
    "    'x2': [0,1,0,1,0,1,0],\n",
    "    'x3': [1,1,1,0,0,1,0],\n",
    "    'y':  [0,1,1,1,1,0,0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  y\n",
       "0   0   0   1  0\n",
       "1   0   1   1  1\n",
       "2   1   0   1  1\n",
       "3   0   1   0  1\n",
       "4   1   0   0  1\n",
       "5   1   1   1  0\n",
       "6   0   0   0  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3\n",
       "0   0   0   1\n",
       "1   0   1   1\n",
       "2   1   0   1\n",
       "3   0   1   0\n",
       "4   1   0   0\n",
       "5   1   1   1\n",
       "6   0   0   0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# documentation on indexing \n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "x = df.loc[:,'x1':'x3']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    0\n",
       "6    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['y']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeding numpy random to have same random numbers at all times\n",
    "np.random.seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Index | w1 | w2 | w3 | w4 |\n",
    "|----|----|----|---|---|\n",
    "Feature 1  | 0  | 0  | 1  | 0 |\n",
    "Feature 2  | 0  | 1  | 1  | 1 |\n",
    "Feature 3  | 1  | 0  | 1  | 1 |\n",
    "\n",
    "W = weight\n",
    "\n",
    "Number of inputs = number of rows for weight\n",
    "Number of outputs/nodes = number of columns for weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a neural  network class. \n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # set up the neural network architecture. \n",
    "        self.inputs = 3\n",
    "        self.hiddenNodes = 4\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # initialize weights\n",
    "        # the resulting weight needs to be 3 rows - input, and \n",
    "        # 4 columns - number of nodes. \n",
    "        # Every feature gets 4 weights\n",
    "        # example of the weights is above\n",
    "        #3 by 4\n",
    "        self.weight1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        #4 by 1\n",
    "        self.weight2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "        \n",
    "    # sigmoid function\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    # feed forward network\n",
    "    def feed_forward(self, X):\n",
    "        \n",
    "        # weighted sum\n",
    "        self.hidden_sum = np.dot(X, self.weight1)\n",
    "        \n",
    "        # activate the output from the hidden layer. \n",
    "        self.activated_hidden_output = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # second weighted sum\n",
    "        self.output_sum = np.dot(self.activated_hidden_output, self.weight2)\n",
    "        \n",
    "        # active the final output from output layer\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output \n",
      " [[0.5388686 ]\n",
      " [0.55352047]\n",
      " [0.40771131]\n",
      " [0.55447957]\n",
      " [0.3955229 ]\n",
      " [0.42425304]\n",
      " [0.53465072]]\n",
      "Actual output \n",
      " 0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    0\n",
      "6    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "output = nn.feed_forward(x)\n",
    "\n",
    "print('Output \\n', output)\n",
    "print('Actual output \\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5388686 ],\n",
       "       [ 0.44647953],\n",
       "       [ 0.59228869],\n",
       "       [ 0.44552043],\n",
       "       [ 0.6044771 ],\n",
       "       [-0.42425304],\n",
       "       [-0.53465072]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making y into one dimensional array\n",
    "y = [[i] for i in y ]\n",
    "\n",
    "# calculating error\n",
    "error = y - output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding back propagation to neural network to improve weights. \n",
    "\n",
    "# building a neural  network class. \n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # set up the neural network architecture. \n",
    "        self.inputs = 3\n",
    "        self.hiddenNodes = 4\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # initialize weights\n",
    "        # the resulting weight needs to be 3 rows - input, and \n",
    "        # 4 columns - number of nodes. \n",
    "        # Every feature gets 4 weights\n",
    "        # example of the weights is above\n",
    "        #3 by 4\n",
    "        self.weight1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        #4 by 1\n",
    "        self.weight2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "        \n",
    "    # sigmoid function\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    # feed forward network\n",
    "    def feed_forward(self, X):\n",
    "        \n",
    "        # weighted sum\n",
    "        self.hidden_sum = np.dot(X, self.weight1)\n",
    "        \n",
    "        # activate the output from the hidden layer. \n",
    "        self.activated_hidden_output = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # second weighted sum\n",
    "        self.output_sum = np.dot(self.activated_hidden_output, self.weight2)\n",
    "        \n",
    "        # active the final output from output layer\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    # define sigmoid derivative\n",
    "    def sigmoidPrime(self, x):\n",
    "        # sigmoid of x\n",
    "        sigmoid_x = self.sigmoid(x)\n",
    "        # derivative of sigmoid\n",
    "        der_sigmoid = sigmoid_x * (1-sigmoid_x)\n",
    "        return der_sigmoid\n",
    "    \n",
    "    def propagation(self, X, y, o):\n",
    "        \"\"\"Back propagation using gradient descent\"\"\"\n",
    "        \n",
    "        # y  =  actual values\n",
    "        # o = predicted values\n",
    "        \n",
    "        # output error\n",
    "        self.output_error = y - o\n",
    "        \n",
    "        # apply derivative of sigmoid to error\n",
    "        # the error multiplied by the derivative of the second weighted sum\n",
    "        # second weighted sum is the final output before sigmoid/activation function\n",
    "        # is applied to the final output. \n",
    "        self.output_delta = self.output_error * self.sigmoidPrime(self.output_sum)\n",
    "        \n",
    "        # what is the error in the second weights. \n",
    "        # second weights is the weight that fed into the final output\n",
    "        self.weight2_error = self.output_delta.dot(self.weight2.T)\n",
    "        \n",
    "        # apply derivate of sigmoid to the first outputs from the hidden layer\n",
    "        # now working on the layer directly above the final output layer\n",
    "        # how much was the original weights that fed into this neural network off?\n",
    "        # multiply the error in the weights that fed into the hidden layer by the \n",
    "        # output of the hidden layer prior to activation. \n",
    "        \n",
    "        self.hidden_delta = self.weight2_error * self.sigmoidPrime(self.hidden_sum)\n",
    "        \n",
    "        # since is is a one hidden layer network, back propagation is done, now\n",
    "        # just update the weights using this new informatiion\n",
    "        \n",
    "        # multiply the input by the new gradient\n",
    "        self.weight1 += X.T.dot(self.hidden_delta)\n",
    "        \n",
    "        # multiply the activated output of the first hidden layer by the \n",
    "        # gradient calculated above. \n",
    "        self.weight2 += self.activated_hidden_output.T.dot(self.output_delta)\n",
    "        \n",
    "    # now implementing the back propagation functioin using a training function\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \n",
    "        # o = the output of the feed forward function\n",
    "        o = self.feed_forward(X)\n",
    "        # implement the backward propagation function during trainig. \n",
    "        self.propagation(X, y, o)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.train(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.38074774]\n",
      " [0.48938583]\n",
      " [0.30611975]\n",
      " [0.57244858]\n",
      " [0.37633517]\n",
      " [0.43185558]\n",
      " [0.46824731]]\n",
      "Loss: \n",
      " 0.2663826122898049\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.42171975]\n",
      " [0.53691614]\n",
      " [0.35397682]\n",
      " [0.60711331]\n",
      " [0.42010271]\n",
      " [0.49158726]\n",
      " [0.50060155]]\n",
      "Loss: \n",
      " 0.2560772745167173\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.44622573]\n",
      " [0.5652214 ]\n",
      " [0.38907335]\n",
      " [0.62803205]\n",
      " [0.45258107]\n",
      " [0.5321184 ]\n",
      " [0.5196704 ]]\n",
      "Loss: \n",
      " 0.25037373854096956\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.45956002]\n",
      " [0.58174162]\n",
      " [0.41468039]\n",
      " [0.64056877]\n",
      " [0.47705522]\n",
      " [0.5602742 ]\n",
      " [0.5299513 ]]\n",
      "Loss: \n",
      " 0.2465931621048934\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.46576255]\n",
      " [0.59125639]\n",
      " [0.43384917]\n",
      " [0.64809249]\n",
      " [0.49616692]\n",
      " [0.58083746]\n",
      " [0.53464807]]\n",
      "Loss: \n",
      " 0.2436343188381287\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.03139913]\n",
      " [0.83894829]\n",
      " [0.83859638]\n",
      " [0.86051314]\n",
      " [0.82406312]\n",
      " [0.32087216]\n",
      " [0.08002559]]\n",
      "Loss: \n",
      " 0.03039258469175723\n",
      "+---------EPOCH 2000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00868806]\n",
      " [0.95034153]\n",
      " [0.93550747]\n",
      " [0.94971669]\n",
      " [0.93792491]\n",
      " [0.08094621]\n",
      " [0.03527445]]\n",
      "Loss: \n",
      " 0.0029827195787943185\n",
      "+---------EPOCH 3000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00582056]\n",
      " [0.96316307]\n",
      " [0.95229659]\n",
      " [0.9624129 ]\n",
      " [0.95426855]\n",
      " [0.05805706]\n",
      " [0.02833629]]\n",
      "Loss: \n",
      " 0.001620596741597181\n",
      "+---------EPOCH 4000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00456154]\n",
      " [0.96928431]\n",
      " [0.96036628]\n",
      " [0.96859027]\n",
      " [0.96201285]\n",
      " [0.04765843]\n",
      " [0.02441322]]\n",
      "Loss: \n",
      " 0.001118859704466769\n",
      "+---------EPOCH 5000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00382991]\n",
      " [0.97308033]\n",
      " [0.96536049]\n",
      " [0.97244662]\n",
      " [0.96678816]\n",
      " [0.04137796]\n",
      " [0.02178525]]\n",
      "Loss: \n",
      " 0.0008554544012490523\n",
      "+---------EPOCH 6000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00334301]\n",
      " [0.9757363 ]\n",
      " [0.96884486]\n",
      " [0.97515367]\n",
      " [0.97011577]\n",
      " [0.03705755]\n",
      " [0.01986395]]\n",
      "Loss: \n",
      " 0.0006926845555810787\n",
      "+---------EPOCH 7000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00299155]\n",
      " [0.97773105]\n",
      " [0.97145482]\n",
      " [0.97719064]\n",
      " [0.97260735]\n",
      " [0.0338514 ]\n",
      " [0.01837921]]\n",
      "Loss: \n",
      " 0.0005820029277966668\n",
      "+---------EPOCH 8000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.0027237 ]\n",
      " [0.97930121]\n",
      " [0.97350445]\n",
      " [0.97879596]\n",
      " [0.97456395]\n",
      " [0.03135037]\n",
      " [0.01718677]]\n",
      "Loss: \n",
      " 0.0005018152736175663\n",
      "+---------EPOCH 9000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00251148]\n",
      " [0.9805793 ]\n",
      " [0.97516943]\n",
      " [0.98010372]\n",
      " [0.97615355]\n",
      " [0.02932895]\n",
      " [0.01620147]]\n",
      "Loss: \n",
      " 0.0004410311980975482\n",
      "+---------EPOCH 10000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00233837]\n",
      " [0.98164616]\n",
      " [0.9765568 ]\n",
      " [0.98119598]\n",
      " [0.97747836]\n",
      " [0.02765128]\n",
      " [0.01536934]]\n",
      "Loss: \n",
      " 0.00039336284430873704\n"
     ]
    }
   ],
   "source": [
    "# train the neural network with multiple epochs\n",
    "\n",
    "# Train my 'net\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "# Number of Epochs / Iterations\n",
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', x)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(x)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(x)))))\n",
    "    nn.train(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8b-r70o8p2Dm"
   },
   "source": [
    "## Try building/training a more complex MLP on a bigger dataset.\n",
    "\n",
    "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
    "\n",
    "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything below was copied from week 2 of tensorflow course assignment notebook in the introduction to tensorflow folder.\n",
    "\n",
    "How to find this notebook \n",
    "\n",
    "- Tensorflow\n",
    "- Coursera Course\n",
    "- Introduction to tensorflow\n",
    "- Week 2\n",
    "- Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MOPtYdk1HgA"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# getting the dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# setting variables to extract datasets from the dataset. \n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2644885e208>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# getting an idea of what images are in our dataset. \n",
    "plt.imshow(train_images[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# finding out the values making up an image\n",
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the values to 0's and 1's\n",
    "train_images = train_images/255\n",
    "test_images = test_images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# designing the model with neural networks\n",
    "model = tf.keras.models.Sequential([keras.layers.Flatten(),\n",
    "                                     keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                     keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a class that will cause our model to stop training when we reach 99% accuracy\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.99):\n",
    "      print('\\nReached 99% accuracy so cancelling training')\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiating callback class. \n",
    "callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1135 - accuracy: 0.9664\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0757 - accuracy: 0.9770\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0559 - accuracy: 0.9830\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0433 - accuracy: 0.9868\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0351 - accuracy: 0.9893\n",
      "Epoch 6/10\n",
      "1854/1875 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9919\n",
      "Reached 99% accuracy so cancelling training\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0264 - accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x264469126d8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the model and fitting the model to training dataset\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs = 10,\n",
    "          callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2120606e-06 1.0598881e-06 1.1565635e-06 6.1077352e-09 9.7347021e-01\n",
      " 2.1343835e-07 3.6659872e-06 1.0435646e-06 2.1514838e-06 2.6517162e-02]\n"
     ]
    }
   ],
   "source": [
    "# testing to see if our model works and if it can detect an image from a new\n",
    "# untested dataset\n",
    "classification = model.predict(test_images)\n",
    "\n",
    "# testing to see if prediction works. \n",
    "print(classification[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# verifying the classificatio i got above\n",
    "print(test_labels[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x264479e2278>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verifying that test image 4 mathes the label above. \n",
    "plt.imshow(test_images[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwlRJSfBlCvy"
   },
   "source": [
    "## Stretch Goals: \n",
    "\n",
    "- Implement Cross Validation model evaluation on your MNIST implementation \n",
    "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
    " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
    "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_432_Backprop_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NNFoundations",
   "language": "python",
   "name": "nnfoundations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
