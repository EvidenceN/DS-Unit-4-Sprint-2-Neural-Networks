{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Backpropagation-Practice\" data-toc-modified-id=\"Backpropagation-Practice-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Backpropagation Practice</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Science-Unit-4-Sprint-2-Assignment-2\" data-toc-modified-id=\"Data-Science-Unit-4-Sprint-2-Assignment-2-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><em>Data Science Unit 4 Sprint 2 Assignment 2</em></a></span></li><li><span><a href=\"#Try-building/training-a-more-complex-MLP-on-a-bigger-dataset.\" data-toc-modified-id=\"Try-building/training-a-more-complex-MLP-on-a-bigger-dataset.-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Try building/training a more complex MLP on a bigger dataset.</a></span></li><li><span><a href=\"#Stretch-Goals:\" data-toc-modified-id=\"Stretch-Goals:-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Stretch Goals:</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Backpropagation Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 0  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 1 |\n",
    "| 0  | 1  | 0  | 1 |\n",
    "| 1  | 0  | 0  | 1 |\n",
    "| 1  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 0  | 0 |\n",
    "\n",
    "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEREYT-3wI1f"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "# create dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'x1': [0,0,1,0,1,1,0],\n",
    "    'x2': [0,1,0,1,0,1,0],\n",
    "    'x3': [1,1,1,0,0,1,0],\n",
    "    'y':  [0,1,1,1,1,0,0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  y\n",
       "0   0   0   1  0\n",
       "1   0   1   1  1\n",
       "2   1   0   1  1\n",
       "3   0   1   0  1\n",
       "4   1   0   0  1\n",
       "5   1   1   1  0\n",
       "6   0   0   0  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3\n",
       "0   0   0   1\n",
       "1   0   1   1\n",
       "2   1   0   1\n",
       "3   0   1   0\n",
       "4   1   0   0\n",
       "5   1   1   1\n",
       "6   0   0   0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# documentation on indexing \n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "x = df.loc[:,'x1':'x3']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    0\n",
       "6    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['y']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeding numpy random to have same random numbers at all times\n",
    "np.random.seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Index | w1 | w2 | w3 | w4 |\n",
    "|----|----|----|---|---|\n",
    "Feature 1  | 0  | 0  | 1  | 0 |\n",
    "Feature 2  | 0  | 1  | 1  | 1 |\n",
    "Feature 3  | 1  | 0  | 1  | 1 |\n",
    "\n",
    "W = weight\n",
    "\n",
    "Number of inputs = number of rows for weight\n",
    "Number of outputs/nodes = number of columns for weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a neural  network class. \n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # set up the neural network architecture. \n",
    "        self.inputs = 3\n",
    "        self.hiddenNodes = 4\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # initialize weights\n",
    "        # the resulting weight needs to be 3 rows - input, and \n",
    "        # 4 columns - number of nodes. \n",
    "        # Every feature gets 4 weights\n",
    "        # example of the weights is above\n",
    "        #3 by 4\n",
    "        self.weight1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        #4 by 1\n",
    "        self.weight2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "        \n",
    "    # sigmoid function\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    # feed forward network\n",
    "    def feed_forward(self, X):\n",
    "        \n",
    "        # weighted sum\n",
    "        self.hidden_sum = np.dot(X, self.weight1)\n",
    "        \n",
    "        # activate the output from the hidden layer. \n",
    "        self.activated_hidden_output = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # second weighted sum\n",
    "        self.output_sum = np.dot(self.activated_hidden_output, self.weight2)\n",
    "        \n",
    "        # active the final output from output layer\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output \n",
      " [[0.5388686 ]\n",
      " [0.55352047]\n",
      " [0.40771131]\n",
      " [0.55447957]\n",
      " [0.3955229 ]\n",
      " [0.42425304]\n",
      " [0.53465072]]\n",
      "Actual output \n",
      " 0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    0\n",
      "6    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "output = nn.feed_forward(x)\n",
    "\n",
    "print('Output \\n', output)\n",
    "print('Actual output \\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5388686 ],\n",
       "       [ 0.44647953],\n",
       "       [ 0.59228869],\n",
       "       [ 0.44552043],\n",
       "       [ 0.6044771 ],\n",
       "       [-0.42425304],\n",
       "       [-0.53465072]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making y into one dimensional array\n",
    "y = [[i] for i in y ]\n",
    "\n",
    "# calculating error\n",
    "error = y - output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding back propagation to neural network to improve weights. \n",
    "\n",
    "# building a neural  network class. \n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # set up the neural network architecture. \n",
    "        self.inputs = 3\n",
    "        self.hiddenNodes = 4\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # initialize weights\n",
    "        # the resulting weight needs to be 3 rows - input, and \n",
    "        # 4 columns - number of nodes. \n",
    "        # Every feature gets 4 weights\n",
    "        # example of the weights is above\n",
    "        #3 by 4\n",
    "        self.weight1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        #4 by 1\n",
    "        self.weight2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "        \n",
    "    # sigmoid function\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    # feed forward network\n",
    "    def feed_forward(self, X):\n",
    "        \n",
    "        # weighted sum\n",
    "        self.hidden_sum = np.dot(X, self.weight1)\n",
    "        \n",
    "        # activate the output from the hidden layer. \n",
    "        self.activated_hidden_output = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # second weighted sum\n",
    "        self.output_sum = np.dot(self.activated_hidden_output, self.weight2)\n",
    "        \n",
    "        # active the final output from output layer\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    # define sigmoid derivative\n",
    "    def sigmoidPrime(self, x):\n",
    "        # sigmoid of x\n",
    "        sigmoid_x = self.sigmoid(x)\n",
    "        # derivative of sigmoid\n",
    "        der_sigmoid = sigmoid_x * (1-sigmoid_x)\n",
    "        return der_sigmoid\n",
    "    \n",
    "    def propagation(self, X, y, o):\n",
    "        \"\"\"Back propagation using gradient descent\"\"\"\n",
    "        \n",
    "        # y  =  actual values\n",
    "        # o = predicted values\n",
    "        \n",
    "        # output error\n",
    "        self.output_error = y - o\n",
    "        \n",
    "        # apply derivative of sigmoid to error\n",
    "        # the error multiplied by the derivative of the second weighted sum\n",
    "        # second weighted sum is the final output before sigmoid/activation function\n",
    "        # is applied to the final output. \n",
    "        self.output_delta = self.output_error * self.sigmoidPrime(self.output_sum)\n",
    "        \n",
    "        # what is the error in the second weights. \n",
    "        # second weights is the weight that fed into the final output\n",
    "        self.weight2_error = self.output_delta.dot(self.weight2.T)\n",
    "        \n",
    "        # apply derivate of sigmoid to the first outputs from the hidden layer\n",
    "        # now working on the layer directly above the final output layer\n",
    "        # how much was the original weights that fed into this neural network off?\n",
    "        # multiply the error in the weights that fed into the hidden layer by the \n",
    "        # output of the hidden layer prior to activation. \n",
    "        \n",
    "        self.hidden_delta = self.weight2_error * self.sigmoidPrime(self.hidden_sum)\n",
    "        \n",
    "        # since is is a one hidden layer network, back propagation is done, now\n",
    "        # just update the weights using this new informatiion\n",
    "        \n",
    "        # multiply the input by the new gradient\n",
    "        self.weight1 += X.T.dot(self.hidden_delta)\n",
    "        \n",
    "        # multiply the activated output of the first hidden layer by the \n",
    "        # gradient calculated above. \n",
    "        self.weight2 += self.activated_hidden_output.T.dot(self.output_delta)\n",
    "        \n",
    "    # now implementing the back propagation functioin using a training function\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \n",
    "        # o = the output of the feed forward function\n",
    "        o = self.feed_forward(X)\n",
    "        # implement the backward propagation function during trainig. \n",
    "        self.propagation(X, y, o)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.train(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.38074774]\n",
      " [0.48938583]\n",
      " [0.30611975]\n",
      " [0.57244858]\n",
      " [0.37633517]\n",
      " [0.43185558]\n",
      " [0.46824731]]\n",
      "Loss: \n",
      " 0.2663826122898049\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.42171975]\n",
      " [0.53691614]\n",
      " [0.35397682]\n",
      " [0.60711331]\n",
      " [0.42010271]\n",
      " [0.49158726]\n",
      " [0.50060155]]\n",
      "Loss: \n",
      " 0.2560772745167173\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.44622573]\n",
      " [0.5652214 ]\n",
      " [0.38907335]\n",
      " [0.62803205]\n",
      " [0.45258107]\n",
      " [0.5321184 ]\n",
      " [0.5196704 ]]\n",
      "Loss: \n",
      " 0.25037373854096956\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.45956002]\n",
      " [0.58174162]\n",
      " [0.41468039]\n",
      " [0.64056877]\n",
      " [0.47705522]\n",
      " [0.5602742 ]\n",
      " [0.5299513 ]]\n",
      "Loss: \n",
      " 0.2465931621048934\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.46576255]\n",
      " [0.59125639]\n",
      " [0.43384917]\n",
      " [0.64809249]\n",
      " [0.49616692]\n",
      " [0.58083746]\n",
      " [0.53464807]]\n",
      "Loss: \n",
      " 0.2436343188381287\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.03139913]\n",
      " [0.83894829]\n",
      " [0.83859638]\n",
      " [0.86051314]\n",
      " [0.82406312]\n",
      " [0.32087216]\n",
      " [0.08002559]]\n",
      "Loss: \n",
      " 0.03039258469175723\n",
      "+---------EPOCH 2000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00868806]\n",
      " [0.95034153]\n",
      " [0.93550747]\n",
      " [0.94971669]\n",
      " [0.93792491]\n",
      " [0.08094621]\n",
      " [0.03527445]]\n",
      "Loss: \n",
      " 0.0029827195787943185\n",
      "+---------EPOCH 3000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00582056]\n",
      " [0.96316307]\n",
      " [0.95229659]\n",
      " [0.9624129 ]\n",
      " [0.95426855]\n",
      " [0.05805706]\n",
      " [0.02833629]]\n",
      "Loss: \n",
      " 0.001620596741597181\n",
      "+---------EPOCH 4000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00456154]\n",
      " [0.96928431]\n",
      " [0.96036628]\n",
      " [0.96859027]\n",
      " [0.96201285]\n",
      " [0.04765843]\n",
      " [0.02441322]]\n",
      "Loss: \n",
      " 0.001118859704466769\n",
      "+---------EPOCH 5000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00382991]\n",
      " [0.97308033]\n",
      " [0.96536049]\n",
      " [0.97244662]\n",
      " [0.96678816]\n",
      " [0.04137796]\n",
      " [0.02178525]]\n",
      "Loss: \n",
      " 0.0008554544012490523\n",
      "+---------EPOCH 6000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00334301]\n",
      " [0.9757363 ]\n",
      " [0.96884486]\n",
      " [0.97515367]\n",
      " [0.97011577]\n",
      " [0.03705755]\n",
      " [0.01986395]]\n",
      "Loss: \n",
      " 0.0006926845555810787\n",
      "+---------EPOCH 7000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00299155]\n",
      " [0.97773105]\n",
      " [0.97145482]\n",
      " [0.97719064]\n",
      " [0.97260735]\n",
      " [0.0338514 ]\n",
      " [0.01837921]]\n",
      "Loss: \n",
      " 0.0005820029277966668\n",
      "+---------EPOCH 8000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.0027237 ]\n",
      " [0.97930121]\n",
      " [0.97350445]\n",
      " [0.97879596]\n",
      " [0.97456395]\n",
      " [0.03135037]\n",
      " [0.01718677]]\n",
      "Loss: \n",
      " 0.0005018152736175663\n",
      "+---------EPOCH 9000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00251148]\n",
      " [0.9805793 ]\n",
      " [0.97516943]\n",
      " [0.98010372]\n",
      " [0.97615355]\n",
      " [0.02932895]\n",
      " [0.01620147]]\n",
      "Loss: \n",
      " 0.0004410311980975482\n",
      "+---------EPOCH 10000---------+\n",
      "Input: \n",
      "    x1  x2  x3\n",
      "0   0   0   1\n",
      "1   0   1   1\n",
      "2   1   0   1\n",
      "3   0   1   0\n",
      "4   1   0   0\n",
      "5   1   1   1\n",
      "6   0   0   0\n",
      "Actual Output: \n",
      " [[0], [1], [1], [1], [1], [0], [0]]\n",
      "Predicted Output: \n",
      " [[0.00233837]\n",
      " [0.98164616]\n",
      " [0.9765568 ]\n",
      " [0.98119598]\n",
      " [0.97747836]\n",
      " [0.02765128]\n",
      " [0.01536934]]\n",
      "Loss: \n",
      " 0.00039336284430873704\n"
     ]
    }
   ],
   "source": [
    "# train the neural network with multiple epochs\n",
    "\n",
    "# Train my 'net\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "# Number of Epochs / Iterations\n",
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', x)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(x)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(x)))))\n",
    "    nn.train(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8b-r70o8p2Dm"
   },
   "source": [
    "## Try building/training a more complex MLP on a bigger dataset.\n",
    "\n",
    "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
    "\n",
    "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MOPtYdk1HgA"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwlRJSfBlCvy"
   },
   "source": [
    "## Stretch Goals: \n",
    "\n",
    "- Implement Cross Validation model evaluation on your MNIST implementation \n",
    "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
    " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
    "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_432_Backprop_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Neural-Network-Foundations",
   "language": "python",
   "name": "neural-network-foundations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
